{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYJvarnUbfRC",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GlobalAveragePooling (GAP)\n",
    "- 입력 Feature map의 채널별로 평균값을 추출하여 1 x 1 x channel 의 Feature map을 생성하는 Pooling\n",
    "- `model.add(keras.layers.GlobalAveragePooling2D())`\n",
    "![gap01](figures/09_gap_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVaIaFDfbfRN",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Feature Extraction layer에서 추출한 Feature map을 Classifier layer로 Flatten해서 전달하면 많은 연결노드와 파라미터가 필요하게된다.     \n",
    "GAP를 사용하면 노드와 파라미터의 개수를 효과적으로 줄일 수 있다.\n",
    "- Feature map의 채널수가 많을 경우 GAP를 사용하는 것이 효과적이나 채널수가 적다면 Flatten을 사용하는 것이 좋다.\n",
    "\n",
    "\n",
    "![gap02](figures/09_gap_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEiUymWcbfRZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pretrained Model\n",
    "\n",
    "- 다른 목적을 위해 미리 학습된 모델.\n",
    "- Pretrained model을 현재 해결하려는 문제에 이용한다.\n",
    "- 대부분 내가 만들려는 네트워크 모델에 포함시켜 사용한다.\n",
    "    - 이런 방식을 Transfer Learning (전이 학습)이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEiUymWcbfRZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras에서 제공하는 Pretrained Model \n",
    "- tensorflow.keras.applications 패키지를 통해 제공\n",
    "    - https://www.tensorflow.org/api_docs/python/tf/keras/applications?hl=ko\n",
    "    - Modules\n",
    "        - 각 모델별 입력 Image 전처리 함수 제공\n",
    "    - Functions\n",
    "        - 각 모델 생성함수\n",
    "- 모델 생성함수의 주요 매개변수\n",
    "    - `weights`: 모델의 학습된 weight 지정. \n",
    "        - 기본값- 'imagenet'. ImageNet 데이터셋으로 학습된 weight를 가진 모델 생성\n",
    "    - `include_top`: fully connected layer(분류기)를 포함할지 여부. True 포함시킴, False: 포함 안 시킴\n",
    "        - False를 지정하면 Feature Extractor인 Convolution Layer들로만 구성된 모델이 생성된다.\n",
    "    - `input_shape`: Input(입력) 이미지의 크기 shape. 3D 텐서로 지정. (높이, 너비, 채널). 기본값: (224,224,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEiUymWcbfRZ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> 딥러닝 모델기반 application 개발시 대부분 Transfer Learning을 한다.  \n",
    "> 다양한 분야에서 다양한 네트워크 모델들이 구현되어 공개 되어 있으며 학습된 Parameter들도 제공되고 있다.  \n",
    "> [paperswithcode](https://paperswithcode.com/)에서 State Of The Art(SOTA) 논문들과 그 구현된 모델을 확인할 수 있다. \n",
    "\n",
    "> State Of The Art(SOTA): 특정 시점에 특정 분야에서 가장 성능이 좋은 모델을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras 제공 Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vgg16_1 = applications.VGG16(weights='imagenet', \n",
    "                                 include_top=False,\n",
    "                                 input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vgg16_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vgg16_2 = applications.VGG16(weights='imagenet', \n",
    "                                 include_top=True,\n",
    "                                 input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vgg16_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(vgg16_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "resnet50 = applications.ResNet50V2(include_top=False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "resnet50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## VGG16 Pretrained 모델을 이용해 이미지 분류\n",
    "- Keras에서 제공하는 Pretrain 모델들은 Image Net 데이터셋을 학습 했다.\n",
    "- 최종 Output 결과로 1000개의 class에 대한 확률을 출력한다.\n",
    "    - Dense(units=1000, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T05:29:17.602657Z",
     "start_time": "2021-11-04T05:29:17.584660Z"
    },
    "id": "p-qaERHebfRZ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### Pretrained Model download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T02:53:15.813180Z",
     "start_time": "2021-11-04T02:52:56.888001Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vgg16 = keras.applications.VGG16()\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 추론할 이미지 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T03:04:35.920718Z",
     "start_time": "2021-11-04T03:04:35.906686Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "img_path = 'test_img/car.jpg'\n",
    "# img_path = 'test_img/bicycle.jpg'\n",
    "\n",
    "img = load_img(img_path, target_size=(224, 224))\n",
    "img_np = img_to_array(img)\n",
    "img_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T03:04:36.683466Z",
     "start_time": "2021-11-04T03:04:36.673468Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "input_tensor = keras.applications.vgg16.preprocess_input(img_np)\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T03:04:37.806098Z",
     "start_time": "2021-11-04T03:04:37.536496Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pred = vgg16.predict(input_tensor[np.newaxis, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T08:10:34.674036Z",
     "start_time": "2021-11-04T08:10:34.541035Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "label = np.argmax(pred, axis=-1)\n",
    "label_class = decode_predictions(pred, top=3)\n",
    "\n",
    "print(\"label num:\", label[0])\n",
    "for idx, lc in enumerate(label_class[0], start=1):\n",
    "    print(f'{idx}. {lc[1]} ({lc[2]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transfer learning (전이학습)\n",
    "- 사전에 학습된 신경망의 구조와 파라미터를 재사용해서 새로운 모델(우리가 만드는 모델)의 시작점으로 삼고 해결하려는 문제를 위해 다시 학습시킨다.\n",
    "- 전이 학습을 통해 다음을 해결할 수 있다.\n",
    "    1. 데이터 부족문제\n",
    "        - 딥러닝은 대용량의 학습데이터가 필요하다.\n",
    "        - 충분한 데이터를 수집하는 것은 항상 어렵다.\n",
    "    2. 과다한 계산량\n",
    "        - 신경망 학습에는 엄청난 양의 계산 자원이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj9RRN6QbfRR",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![transfer_learning01](figures/09_transfer_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dXETWizbfRS",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 미리 학습된(pre-trained) Model을 이용하여 모델을 구성한 뒤 현재 하려는 예측 문제를 해결한다.\n",
    "- 보통 Pretrained Model에서 Feature Extraction 부분을 사용한다.\n",
    "    - Computer Vision 문제의 경우 Bottom 쪽의 Convolution Layer(Feature Extractor)들은 이미지에 나타나는 일반적인 특성을 추출하므로 **다른 대상을 가지고 학습했다고 하더라도 재사용할 수 있다.**\n",
    "    - Top 부분 Layer 부분은 특히 출력 Layer의 경우 대상 데이터셋의 목적에 맞게 변경 해야 하므로 재사용할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnS6S0QPbfRT",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![transfer_learning02](figures/09_transfer_02.png)\n",
    "\n",
    "> **Frozon**: Training시 parameter가 update 되지 않도록 하는 것을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRLhG6D8bfRb",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Feature extraction 재사용\n",
    "- Pretrained Model에서 Feature Extractor 만 가져오고 추론기(Fully connected layer)만 새로 정의한 뒤 그 둘을 합쳐서 모델을 만든다.\n",
    "- 학습시 직접 구성한 추론기만 학습되도록 한다.\n",
    "    - Feature Extractor는 추론을 위한 Feature 추출을 하는 역할만 하고 그 parameter(weight)가 학습되지 않도록 한다.\n",
    "- Keras에서 모델/레이어의 parameter trainable 속성 변경\n",
    "    -  **Layer.trainable=False**\n",
    "        - Layer의 trainable 속성을 변경\n",
    "    - **Model.trainable=False**\n",
    "        - 모델내의 모든 Layer들의 trainable 속성을 변경\n",
    "    - trainable 속성변경은 **모델 컴파일 전에** 해야 한다.\n",
    "        \n",
    "#### Backbone, Base network\n",
    "전체 네트워크에서 Feature Extraction의 역할을 담당하는 부분을 backbone/base network라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 4429,
     "status": "ok",
     "timestamp": 1619495130756,
     "user": {
      "displayName": "김성환",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqNkeEG8Sp5Fmsq56VZoiRsSxwUXmtH2Mb14M3YQA=s64",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "u2xEPmIQbfRO",
    "outputId": "e669b58c-b03c-41ef-cf71-2e8503998c4f",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 이미지 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T03:28:45.578697Z",
     "start_time": "2021-11-04T03:28:38.826378Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 4429,
     "status": "ok",
     "timestamp": 1619495130756,
     "user": {
      "displayName": "김성환",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqNkeEG8Sp5Fmsq56VZoiRsSxwUXmtH2Mb14M3YQA=s64",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "u2xEPmIQbfRO",
    "outputId": "e669b58c-b03c-41ef-cf71-2e8503998c4f",
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "url = 'https://drive.google.com/uc?id=1nBE3N2cXQGwD8JaD0JZ2LmFD-n3D5hVU'\n",
    "fname = 'cats_and_dogs_small.zip'\n",
    "gdown.download(url, fname, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T04:02:05.832170Z",
     "start_time": "2021-11-04T04:02:00.227219Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#zipfile모듈: Zip 압축파일을 다루는 모듈(압축하기, 풀기)\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# 압축풀기: ZipFile(압축파일경로).extractall(풀경로)\n",
    "with ZipFile(fname) as zipFile:\n",
    "    zipFile.extractall(os.path.join('data','cats_and_dogs_small'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T04:05:17.474823Z",
     "start_time": "2021-11-04T04:05:14.922641Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T04:05:17.490701Z",
     "start_time": "2021-11-04T04:05:17.475699Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 20\n",
    "N_BATCHS = 100\n",
    "\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Util 함수 정의\n",
    "##### 추론함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T05:22:54.821221Z",
     "start_time": "2021-11-04T05:22:54.816218Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def predict_cat_dog(img_path, model, preprocess_input):\n",
    "    \"\"\"\n",
    "    이미지를 받아서 모델을 이용해 추론 후 결과를 반환하는 함수\n",
    "    [파라미터]\n",
    "        img_path: str - 분류(추론)할 이미지 경로\n",
    "        model: 학습된 모델 객체\n",
    "        preprocess_input: 이미지 전처리 함수\n",
    "        model: conv_base(convolution)을 통해 feature를 추출할지 여부\n",
    "    [반환값]\n",
    "        tuple: (예측확률, 예측라벨 index, 예측라벨명)\n",
    "    \"\"\"\n",
    "    class_names = ['Cat', 'Dog']\n",
    "    img = load_img(img_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "    img_np = img_to_array(img)\n",
    "    img_np = img_np[np.newaxis, ...]\n",
    "    \n",
    "    input_tensor = preprocess_input(img_np)\n",
    "        \n",
    "    pred = model.predict(input_tensor)[0][0]\n",
    "    pred_class = int(np.where(pred<=0.5, 0, 1))\n",
    "    pred_label = class_names[pred_class]\n",
    "    \n",
    "    return pred, pred_class, pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### ImageDataGenerator 를 생성하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T04:05:17.522701Z",
     "start_time": "2021-11-04T04:05:17.507735Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_generator(preprocess_input):\n",
    "    \"\"\"\n",
    "    train/validation/test 용 ImageDataGenerator 생성해서 반환하는 함수\n",
    "    [파라미터]\n",
    "        preprocess_input: 전처리 함수\n",
    "    [반환값]\n",
    "        tuple: (train iter, validation iter, test iter)\n",
    "    \"\"\"\n",
    "    train_dir = \"data/cats_and_dogs_small/train/\"\n",
    "    val_dir = 'data/cats_and_dogs_small/validation/'\n",
    "    test_dir = 'data/cats_and_dogs_small/test'\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, \n",
    "                                       rotation_range=40, \n",
    "                                       brightness_range=[0.7, 1.3], \n",
    "                                       zoom_range=0.2, \n",
    "                                       horizontal_flip=True, \n",
    "                                       width_shift_range=0.2, \n",
    "                                       height_shift_range=0.2, \n",
    "                                       fill_mode='constant')\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    \n",
    "    \n",
    "    train_iter = train_datagen.flow_from_directory(train_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=N_BATCHS, class_mode='binary')\n",
    "    val_iter = val_datagen.flow_from_directory(val_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=N_BATCHS, class_mode='binary')\n",
    "    test_iter = test_datagen.flow_from_directory(test_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=N_BATCHS, class_mode='binary')\n",
    "    \n",
    "    return train_iter, val_iter, test_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### train/validation/test 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T04:05:17.901991Z",
     "start_time": "2021-11-04T04:05:17.524699Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = get_generator(applications.vgg16.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 모델정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T04:05:18.868153Z",
     "start_time": "2021-11-04T04:05:18.850120Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def create_model1(backbone):\n",
    "    \"\"\"\n",
    "    Feature Exctractor 모델을 받아서 개/고양이 분류 모델을 만들어 반환\n",
    "    [Parameter]\n",
    "        backbone: Feature Exctractor\n",
    "    [Return]\n",
    "        model\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    backbone.trainable = False\n",
    "    model.add(backbone)\n",
    "    \n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T04:05:21.224297Z",
     "start_time": "2021-11-04T04:05:19.242645Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "backbone = applications.VGG16(include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "model1 = create_model1(backbone)\n",
    "\n",
    "model1.compile(optimizer=keras.optimizers.Adam(LEARNING_RATE), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T04:05:21.757464Z",
     "start_time": "2021-11-04T04:05:21.746464Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T04:05:22.508408Z",
     "start_time": "2021-11-04T04:05:22.299412Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model1, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T04:07:21.537427Z",
     "start_time": "2021-11-04T04:05:24.218438Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hist = model1.fit(train_iter, epochs=N_EPOCHS, \n",
    "                   steps_per_epoch=len(train_iter), \n",
    "                   validation_data=val_iter,\n",
    "                   validation_steps=len(val_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot(range(1, N_EPOCHS+1), hist.history['loss'], label='train loss')\n",
    "plt.plot(range(1, N_EPOCHS+1), hist.history['val_loss'], label='validation loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T04:07:48.173856Z",
     "start_time": "2021-11-04T04:07:36.514611Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model1.evaluate(test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T05:31:27.590505Z",
     "start_time": "2021-11-04T05:31:27.385489Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predict_cat_dog('cat.jpg', model1, applications.vgg16.preprocess_input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T05:26:17.648689Z",
     "start_time": "2021-11-04T05:26:17.473693Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predict_cat_dog('dog.jpg', model1, applications.vgg16.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miqV_0WSbfRm",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fine-tuning(미세조정)\n",
    "- Transfer Learning을 위한 Pretrained 모델을 내가 학습시켜야 하는 데이터셋(Custom Dataset)으로 재학습시키는 것을 fine tunning 이라고 한다.\n",
    "- 주어진 문제에 더 적합하도록 Feature Extractor의 가중치들도 조정 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "py7c3rmmbfRm",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fine tuning 전략\n",
    "![transfer02](figures/09_transfer_03.png)\n",
    "\n",
    "- **세 전략 모두 추론기는 train한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wtxXsYUbfRn",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. **<font size='5'>전체 모델을 전부 학습시킨다.(1번)</font>**\n",
    "    - Pretrained 모델의 weight는 Feature extraction 의 초기 weight 역할을 한다.\n",
    "    - **Train dataset의 양이 많고** Pretrained 모델이 학습했던 dataset과 Custom dataset의 class간의 유사성이 **낮은 경우** 적용.\n",
    "    - 학습에 시간이 많이 걸린다.\n",
    "    \n",
    "    \n",
    "2. **<font size='5'>Pretrained 모델 Bottom layer들(Input과 가까운 Layer들)은 고정시키고 Top layer의 일부를 재학습시킨다.(2번)</font>**\n",
    "    - **Train dataset의 양이 많고** Pretrained 모델이 학습했던 dataset과 Custom dataset의 class간의 유사성이 **높은 경우** 적용.\n",
    "    - **Train dataset의 양이 적고** Pretained 모델이 학습했던 dataset과 custom dataset의 class간의 유사성이 **낮은 경우** 적용\n",
    "    \n",
    "    \n",
    "3. **<font size='5'>Pretrained 모델 전체를 고정시키고 classifier layer들만 학습시킨다.(3번)</font>**\n",
    "    - **Train dataset의 양이 적고** Pretrained 모델이 학습했던 dataset과 Custom dataset의 class간의 유사성이 **높은 경우** 적용.\n",
    "  \n",
    "  \n",
    "> **Custom dataset:** 내가 학습시키고자 하는 dataset \n",
    "\n",
    "> 1번 2번 전략을 Fine tuning 이라고 한다.\n",
    "\n",
    "![fine tuning](figures/09_finetuning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model, Layer의 weight 조회\n",
    "\n",
    "### Model에서 Layer들 조회\n",
    "- model객체.layers\n",
    "    - 모델을 구성하는 layer 객체들을 담은 리스트\n",
    "- model객체.get_layer(Layer이름:str)\n",
    "    - argument로 전달한 이름의 Layer객체를 반환\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Model과 Layer의 weight들 조회 및 설정\n",
    "- Layer와 Model은 **Weight 조회**와 관련해 세가지 **속성**을 제공\n",
    "    - **weights:** 레이어의 모든 weight 변수들을 담은 리스트\n",
    "        - get_weights() : 레이어의 모든 weight 변수 리스트를 카피해서 반환한다.\n",
    "    - **trainable_weights:** Train(학습)시 업데이트 되는 weights들 리스트\n",
    "    - **non_trainable_weights:** Train(학습)시 업데이트 되지 않는(훈련되지 않는) weights들 리스트\n",
    "- Layer와 Model은 boolean 값을 가지는 속성 **`trainable`**을 제공\n",
    "    - trainable을 **False로** 설정하면 Layer의 weights들이 훈련가능에서 **훈련 불가능** 상태로 변경된다. 이런 상태를 **Frozen-동결** 이라고 하며 학습시 weight들이 업데이트 되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:04:53.248978Z",
     "start_time": "2021-11-04T06:04:53.178951Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "test_model = keras.Sequential()\n",
    "test_model.add(layers.Conv2D(filters=32, kernel_size=3,  padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "test_model.add(layers.MaxPooling2D(padding='same'))\n",
    "\n",
    "test_model.add(layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "test_model.add(layers.MaxPooling2D(padding='same'))\n",
    "\n",
    "test_model.add(layers.Flatten())\n",
    "test_model.add(layers.Dense(units=128, activation='relu'))\n",
    "test_model.add(layers.Dense(units=1, activation='sigmoid', name='output'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:04:53.468793Z",
     "start_time": "2021-11-04T06:04:53.457767Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:04:53.814149Z",
     "start_time": "2021-11-04T06:04:53.802183Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_layers = test_model.layers\n",
    "print(type(test_layers), len(test_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:05:14.931079Z",
     "start_time": "2021-11-04T06:05:14.924115Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_layers[0], test_layers[1], test_layers[6], test_layers[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:05:32.138887Z",
     "start_time": "2021-11-04T06:05:32.129886Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_layers[0].name, test_layers[6].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:05:41.522727Z",
     "start_time": "2021-11-04T06:05:41.506728Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "output_layer = test_model.get_layer(\"output\")\n",
    "output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:09:34.145404Z",
     "start_time": "2021-11-04T06:09:34.138405Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "conv_layer_1 = test_model.get_layer('conv2d')\n",
    "conv_layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:09:25.231155Z",
     "start_time": "2021-11-04T06:09:25.226179Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "max_pooling2d_1 = test_model.get_layer('max_pooling2d_1')\n",
    "max_pooling2d_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:06:57.299003Z",
     "start_time": "2021-11-04T06:06:57.290001Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_params = test_model.weights\n",
    "type(model_params), len(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:09:36.996385Z",
     "start_time": "2021-11-04T06:09:36.978357Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "param = conv_layer_1.weights\n",
    "\n",
    "type(param), len(param) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:10:38.417372Z",
     "start_time": "2021-11-04T06:10:38.411371Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "param[0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:11:44.708353Z",
     "start_time": "2021-11-04T06:11:44.690320Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "param[1].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:09:58.088704Z",
     "start_time": "2021-11-04T06:09:58.073705Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "max_pooling2d_1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:12:14.787301Z",
     "start_time": "2021-11-04T06:12:14.779244Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(conv_layer_1.trainable)\n",
    "conv_layer_1.trainable = False\n",
    "print(conv_layer_1.trainable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:13:00.182881Z",
     "start_time": "2021-11-04T06:13:00.169881Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9iEOpsCbfRr",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fine Tuning 예제\n",
    "\n",
    "#### Pretrained 모델 Bottom layer들(Input과 가까운 Layer들)은 고정시키고 Top layer의 일부를 재학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGgjrGaIbfRr",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Conv_base에서 가장 Top부분에 있는 레이어에 대해 fine-tuning.\n",
    "    - 앞의 layer들은 비교적 일반적이고 재사용 가능한 feature를 학습\n",
    "    - 너무 많은 parameter를 학습시키면 overfitting의 위험이 있음 (특히 새로운 데이터의 수가 적을 때)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:21:17.929704Z",
     "start_time": "2021-11-04T06:21:17.906674Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 하이퍼파라미터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:21:18.508204Z",
     "start_time": "2021-11-04T06:21:18.490170Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 20\n",
    "N_BATCHS = 100\n",
    "\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 모델 정의, 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:21:19.573969Z",
     "start_time": "2021-11-04T06:21:19.554937Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def create_model2():\n",
    "    \"\"\"\n",
    "    VGG16에서 block5_conv2, block5_conv3 은 학습 가능하도록 fine tuning을 한다.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    backbone = applications.VGG16(include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "    is_trainable = False\n",
    "    for layer in backbone.layers:\n",
    "        if layer.name == 'block5_conv2':\n",
    "            is_trainable = True\n",
    "        layer.trainable = is_trainable\n",
    "    \n",
    "    model.add(backbone)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:21:37.121867Z",
     "start_time": "2021-11-04T06:21:36.722771Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model2 = create_model2()\n",
    "model2.compile(optimizer=keras.optimizers.Adam(LEARNING_RATE), \n",
    "                loss='binary_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:21:51.012690Z",
     "start_time": "2021-11-04T06:21:51.002654Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 838,
     "status": "ok",
     "timestamp": 1619498916479,
     "user": {
      "displayName": "김성환",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqNkeEG8Sp5Fmsq56VZoiRsSxwUXmtH2Mb14M3YQA=s64",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "gWcsY_TLbfRs",
    "outputId": "b1524c93-6323-4e8a-b8a4-919cd38dce9d",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### callback 설정\n",
    "- 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "save_path = 'path'\n",
    "\n",
    "mc_callback = keras.callbacks.ModelCheckpoint(filepath=save_path, save_best_only=True, monitor='val_loss', verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:25:34.086072Z",
     "start_time": "2021-11-04T06:24:16.003303Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hist = model2.fit(train_iter, \n",
    "                   epochs=N_EPOCHS, \n",
    "                   steps_per_epoch=len(train_iter), \n",
    "                   validation_data=val_iter, \n",
    "                   validation_steps=len(val_iter), \n",
    "#                    callbacks=[mc_callback]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:27:07.852991Z",
     "start_time": "2021-11-04T06:27:07.706983Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot(range(1, N_EPOCHS+1), hist.history['loss'], label='train loss')\n",
    "plt.plot(range(1, N_EPOCHS+1), hist.history['val_loss'], label='validation loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 최종 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T06:28:00.482878Z",
     "start_time": "2021-11-04T06:27:49.002880Z"
    },
    "id": "hRUw49g0bfRt",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model2.evaluate(test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_cat_dog('cat.jpg', model2, applications.vgg16.preprocess_input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_cat_dog('dog.jpg', model2, applications.vgg16.preprocess_input) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "xFiHZghabfRV",
    "CSgxoXQsbfRV",
    "Lm9kqHnzbfRW",
    "D_gLQChqbfRX",
    "djrKpnvkbfRY",
    "ZEiUymWcbfRZ"
   ],
   "name": "10_GAP_Transfer Learning(전이학습).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "551.4px",
    "left": "1166px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
